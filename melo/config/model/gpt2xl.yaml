name: gpt2-xl
class_name: GPT2LMHeadModel
tokenizer_class: GPT2TokenizerFast
tokenizer_name: gpt2-xl

fan_in_fan_out: True
target_modules:
  - transformer.h.36.mlp.c_fc
  - transformer.h.37.mlp.c_fc


#pt: null
pt: /home/yu/ECNU/MELO/melo/checkpoint # set this to 'hallucination' inside your checkpoint directory
#model.base_model.h[35]



grace_layer: transformer.h.35.mlp.c_fc